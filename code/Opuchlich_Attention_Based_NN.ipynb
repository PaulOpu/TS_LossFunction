{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import codecs\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "from feature_extraction import TextFeatureCreator\n",
    "\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 10.0)) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#zip_ref = zipfile.ZipFile(\"clean_newsela_article_files.zip\", 'r')\n",
    "#zip_ref.extractall(\"clean_newsela\")\n",
    "#zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Based Neural Networks\n",
    "\n",
    "## Import Section\n",
    "\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21490"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import training and test set\n",
    "df = pd.read_csv(\"/data/ts_cost_function/newsela_article_feature_scores_V2.csv\",sep=\";\")\n",
    "df = df.loc[~df[\"path\"].str.contains(\"LSAT\")]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Scorer\n",
    "ts = TextFeatureCreator(\"/data/ts_cost_function/LSATtexts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.60611227e+00, 3.10202027e+01, 3.18078798e-01, 4.72160037e+01,\n",
       "       4.57929050e-01, 7.43301324e+00, 4.42320513e+00, 2.82743677e+00,\n",
       "       1.52766676e+00, 1.39530366e+00, 1.08050328e+00, 6.62886357e-01,\n",
       "       1.08484166e+00, 1.20740261e-01, 3.11994654e-01, 1.65647696e-02,\n",
       "       1.52961211e+00, 1.98660670e-01, 3.44356431e+00, 3.82638558e+00])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.feature_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset\n",
    "\n",
    "### Number of different Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/data/ts_cost_function/clean_newsela/\"\n",
    "#test_path = test_path[:5] + \"clean_\" + test_path[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_file_text(df):\n",
    "    for ind,row in df.iterrows():\n",
    "        if row[\"path\"] != 'data/LSATtexts.txt':\n",
    "            yield get_file_text(row,tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_text(row,tokenize=True):\n",
    "    path = row[\"path\"].split(\"/\")[-1]\n",
    "    path= \"/data/ts_cost_function/clean_newsela/\"+path\n",
    "    #if row[\"dataset\"] == \"newsela\":\n",
    "    #    path = row[\"path\"][:5] + \"clean_\" + row[\"path\"][5:]\n",
    "    with codecs.open(path, \"r\",encoding='utf-8', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "        if tokenize:\n",
    "            text = [[word.text.lower() for word in nlp(sent)] for sent in text.split(\".\")]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eng_words(eng_words_path=\"data/20k_words.txt\"):\n",
    "\n",
    "    with open(eng_words_path,\"r\") as f:\n",
    "        data = f.read()\n",
    "        words = data.split(\"\\n\")\n",
    "        english_df = pd.DataFrame(data=words,columns=[\"word\"])\n",
    "        english_df[\"index\"] = range(0,len(english_df))\n",
    "    return english_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [get_file_text(row) for ind,row in tqdm(df.iterrows()) if row[\"path\"] != 'data/LSATtexts.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_set = set()\n",
    "counter = Counter()\n",
    "for ind,row in tqdm(df.iterrows()):\n",
    "    lem_text = [token.lemma_ for token in nlp(get_file_text(row))]\n",
    "    counter.update(lem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/newsela_word_set.txt\",\"w\") as f:\n",
    "    f.write(\",\".join(word_set))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15419"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_array = np.array(list(word_set))\n",
    "english_df = load_eng_words()\n",
    "len(word_set.intersection(english_df[\"word\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Sentences and Words per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_stats(df):\n",
    "    sents = []\n",
    "    words = []\n",
    "    removed = []\n",
    "    for ind,text in enumerate(yield_file_text(df)):\n",
    "        sent_split = sent_tokenize(text)\n",
    "        sents.append(len(sent_split))\n",
    "        words.append([word_tokenize(sent) for sent in sent_split])\n",
    "        if text.find(\"This article has been removed\") >= 0:\n",
    "            removed.append(ind)\n",
    "    \n",
    "    print(\"Max #Sents: {}\".format(np.max(sents)))\n",
    "    print(\"Min #Sents: {}\".format(np.min(sents)))\n",
    "    print(\"Std #Sents: {}\".format(np.std(sents)))\n",
    "    plt.boxplot(sents)\n",
    "    plt.show()\n",
    "    \n",
    "    return sents,words,removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max #Sents: 204\n",
      "Min #Sents: 11\n",
      "Std #Sents: 12.270055057859112\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sents,words,removed = sentence_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2571fbe7b285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Max Word Count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "#Max Word Count\n",
    "np.max([np.max(article) for article in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.720281280318863"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean Word Count\n",
    "np.mean([sent for art in words for sent in art])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add lemmatize text to feature scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_file(df,transform_fn,tokenize=False):\n",
    "    df[\"text\"] = df.apply(lambda row: transform_fn(get_file_text(row,tokenize)),axis=1)\n",
    "    return df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemma_text=[]\n",
    "    lemma_sent = []\n",
    "    for token in nlp(text.lower()):\n",
    "        if token.is_sent_start == True:\n",
    "            lemma_text.append(lemma_sent)\n",
    "            lemma_sent = []\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            lemma_sent.append(token.lemma_)\n",
    "        else:\n",
    "            lemma_sent.append(token.text)\n",
    "    return lemma_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = create_dataset_file(df,lemmatize_text,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/data/ts_cost_function/dataset_features_and_text.csv\",index=False,sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/ts_cost_function/dataset_features_and_text.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sent_for_word2vec(text_list):\n",
    "    text_parts,text_part = [],[]\n",
    "    text_part_len = 0\n",
    "    for text in text_list:\n",
    "        text_len = len(text)\n",
    "        if text_part_len + text_len < 900000:\n",
    "            text_part_len += text_len\n",
    "            text_part += [text]\n",
    "        else:\n",
    "            text_parts += [\" \".join(text_part)]\n",
    "            text_part_len = 0\n",
    "            text_part = []\n",
    "    return text_parts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = df[\"text\"].values\n",
    "text_parts = prepare_sent_for_word2vec(text_list)\n",
    "\n",
    "hole_lem_text = [lemmatize_text(text) for text in tqdm(text_parts)]\n",
    "hole_text_sents = np.concatenate(hole_lem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_word2vec_model = Word2Vec(hole_text_sents, size=50, window=4, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_word2vec_model.save(\"/data/ts_cost_function/word2vec_lem.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.2452955 , -2.1530788 ,  1.7280709 , -0.9999138 , -1.1060853 ,\n",
       "        0.3383382 , -1.1418934 ,  2.2745516 , -0.2513405 , -0.82757384,\n",
       "       -0.7249763 ,  1.7150258 ,  2.44857   , -3.9633307 , -1.7148128 ,\n",
       "       -0.02097538,  4.4459324 ,  0.41563603,  0.43043882, -0.21437858,\n",
       "       -2.0976083 ,  3.0210202 ,  0.19070254,  2.732013  , -0.02442212,\n",
       "        3.6682212 ,  0.86653304,  1.7804645 , -0.8916921 ,  2.6753292 ,\n",
       "       -0.75225073, -2.1348693 ,  1.1207342 , -1.9519628 ,  1.996752  ,\n",
       "       -2.7731352 ,  1.3074355 ,  3.1944182 , -2.046747  , -0.01732185,\n",
       "       -0.9517765 ,  0.7973166 ,  0.5044691 , -1.0322701 ,  3.7471695 ,\n",
       "       -0.25170118,  2.2080932 , -3.2449086 , -3.4603064 , -0.67942697],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_word2vec_model.wv[\"do\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exchange lemmatized text by word2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[one, of, the, big, threat, to, the, kea, be,...\n",
       "1    [[drone, help, keep, swimmer, and, surfer, saf...\n",
       "2    [[a, california, company, have, make, old, tim...\n",
       "3    [[the, drama, teacher, at, the, parkland, ,, f...\n",
       "4    [[he, be, the, first, democrat, to, be, elect,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5].apply(lambda x: ast.literal_eval(x[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>feature_sums</th>\n",
       "      <th>regression_score</th>\n",
       "      <th>Mean word length</th>\n",
       "      <th>Mean sentence length</th>\n",
       "      <th>Basic english ratio</th>\n",
       "      <th>Syllables per sentence</th>\n",
       "      <th>Type token ratio</th>\n",
       "      <th>#nouns</th>\n",
       "      <th>#verbs</th>\n",
       "      <th>...</th>\n",
       "      <th>Complements</th>\n",
       "      <th>Coordination</th>\n",
       "      <th>Apposition</th>\n",
       "      <th>Passive verbs</th>\n",
       "      <th>Parataxis</th>\n",
       "      <th>Auxiliary Verbs</th>\n",
       "      <th>Negation</th>\n",
       "      <th>Prepositional Phrases</th>\n",
       "      <th>Modifiers</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/kea-extin...</td>\n",
       "      <td>7.687178</td>\n",
       "      <td>0.326461</td>\n",
       "      <td>0.909090</td>\n",
       "      <td>0.306252</td>\n",
       "      <td>1.298557</td>\n",
       "      <td>0.263046</td>\n",
       "      <td>0.845914</td>\n",
       "      <td>0.365935</td>\n",
       "      <td>0.465726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603422</td>\n",
       "      <td>0.202795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366106</td>\n",
       "      <td>0.201348</td>\n",
       "      <td>0.203278</td>\n",
       "      <td>0.256116</td>\n",
       "      <td>[[one, of, the, big, threat, to, the, kea, be,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/australia...</td>\n",
       "      <td>16.690378</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.995979</td>\n",
       "      <td>0.841234</td>\n",
       "      <td>1.016792</td>\n",
       "      <td>0.804812</td>\n",
       "      <td>1.071948</td>\n",
       "      <td>1.044247</td>\n",
       "      <td>0.968916</td>\n",
       "      <td>...</td>\n",
       "      <td>1.234272</td>\n",
       "      <td>0.796094</td>\n",
       "      <td>1.129397</td>\n",
       "      <td>0.437070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950924</td>\n",
       "      <td>0.686415</td>\n",
       "      <td>0.712792</td>\n",
       "      <td>0.855305</td>\n",
       "      <td>[[drone, help, keep, swimmer, and, surfer, saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/city-trol...</td>\n",
       "      <td>8.278258</td>\n",
       "      <td>0.352503</td>\n",
       "      <td>0.955849</td>\n",
       "      <td>0.313058</td>\n",
       "      <td>1.250405</td>\n",
       "      <td>0.273918</td>\n",
       "      <td>0.879494</td>\n",
       "      <td>0.373708</td>\n",
       "      <td>0.457185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360741</td>\n",
       "      <td>0.240468</td>\n",
       "      <td>0.180049</td>\n",
       "      <td>0.278712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440578</td>\n",
       "      <td>0.437714</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.306794</td>\n",
       "      <td>[[a, california, company, have, make, old, tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/parkland-...</td>\n",
       "      <td>12.440091</td>\n",
       "      <td>0.538971</td>\n",
       "      <td>0.846982</td>\n",
       "      <td>0.603712</td>\n",
       "      <td>0.943163</td>\n",
       "      <td>0.505093</td>\n",
       "      <td>0.689046</td>\n",
       "      <td>0.619676</td>\n",
       "      <td>0.733049</td>\n",
       "      <td>...</td>\n",
       "      <td>1.106273</td>\n",
       "      <td>0.442461</td>\n",
       "      <td>1.325159</td>\n",
       "      <td>0.128207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496858</td>\n",
       "      <td>0.805393</td>\n",
       "      <td>0.391068</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>[[the, drama, teacher, at, the, parkland, ,, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/nyc-elect...</td>\n",
       "      <td>9.679800</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.947809</td>\n",
       "      <td>0.433960</td>\n",
       "      <td>1.017136</td>\n",
       "      <td>0.382856</td>\n",
       "      <td>0.848541</td>\n",
       "      <td>0.602820</td>\n",
       "      <td>0.547810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551202</td>\n",
       "      <td>0.372263</td>\n",
       "      <td>0.637095</td>\n",
       "      <td>0.493105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440031</td>\n",
       "      <td>0.290406</td>\n",
       "      <td>0.379750</td>\n",
       "      <td>0.316627</td>\n",
       "      <td>[[he, be, the, first, democrat, to, be, elect,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  feature_sums  \\\n",
       "0  /data/ts_cost_function/clean_newsela/kea-extin...      7.687178   \n",
       "1  /data/ts_cost_function/clean_newsela/australia...     16.690378   \n",
       "2  /data/ts_cost_function/clean_newsela/city-trol...      8.278258   \n",
       "3  /data/ts_cost_function/clean_newsela/parkland-...     12.440091   \n",
       "4  /data/ts_cost_function/clean_newsela/nyc-elect...      9.679800   \n",
       "\n",
       "   regression_score  Mean word length  Mean sentence length  \\\n",
       "0          0.326461          0.909090              0.306252   \n",
       "1          0.769983          0.995979              0.841234   \n",
       "2          0.352503          0.955849              0.313058   \n",
       "3          0.538971          0.846982              0.603712   \n",
       "4          0.476461          0.947809              0.433960   \n",
       "\n",
       "   Basic english ratio  Syllables per sentence  Type token ratio    #nouns  \\\n",
       "0             1.298557                0.263046          0.845914  0.365935   \n",
       "1             1.016792                0.804812          1.071948  1.044247   \n",
       "2             1.250405                0.273918          0.879494  0.373708   \n",
       "3             0.943163                0.505093          0.689046  0.619676   \n",
       "4             1.017136                0.382856          0.848541  0.602820   \n",
       "\n",
       "     #verbs                        ...                          Complements  \\\n",
       "0  0.465726                        ...                             0.603422   \n",
       "1  0.968916                        ...                             1.234272   \n",
       "2  0.457185                        ...                             0.360741   \n",
       "3  0.733049                        ...                             1.106273   \n",
       "4  0.547810                        ...                             0.551202   \n",
       "\n",
       "   Coordination  Apposition  Passive verbs  Parataxis  Auxiliary Verbs  \\\n",
       "0      0.202795    0.000000       0.256415        0.0         0.366106   \n",
       "1      0.796094    1.129397       0.437070        0.0         0.950924   \n",
       "2      0.240468    0.180049       0.278712        0.0         0.440578   \n",
       "3      0.442461    1.325159       0.128207        0.0         0.496858   \n",
       "4      0.372263    0.637095       0.493105        0.0         0.440031   \n",
       "\n",
       "   Negation  Prepositional Phrases  Modifiers  \\\n",
       "0  0.201348               0.203278   0.256116   \n",
       "1  0.686415               0.712792   0.855305   \n",
       "2  0.437714               0.183076   0.306794   \n",
       "3  0.805393               0.391068   0.282251   \n",
       "4  0.290406               0.379750   0.316627   \n",
       "\n",
       "                                                text  \n",
       "0  [[one, of, the, big, threat, to, the, kea, be,...  \n",
       "1  [[drone, help, keep, swimmer, and, surfer, saf...  \n",
       "2  [[a, california, company, have, make, old, tim...  \n",
       "3  [[the, drama, teacher, at, the, parkland, ,, f...  \n",
       "4  [[he, be, the, first, democrat, to, be, elect,...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data/ts_cost_function/dataset_features_and_text.csv\",sep=\"|\")\n",
    "df[\"text\"] = df.apply(lambda x: ast.literal_eval(x[\"text\"]),axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_word2vec_model = Word2Vec.load(\"/data/ts_cost_function/word2vec_lem.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(word2vec_model,text):\n",
    "    vectorized_text = [\n",
    "            [word2vec_model.wv[word] \n",
    "             for word in sent if word in lem_word2vec_model.wv.vocab] \n",
    "         for sent in text]\n",
    "    \n",
    "    #print(vectorized_text)\n",
    "    vectorized_text = [sent for sent in vectorized_text if sent]\n",
    "    return vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>feature_sums</th>\n",
       "      <th>regression_score</th>\n",
       "      <th>Mean word length</th>\n",
       "      <th>Mean sentence length</th>\n",
       "      <th>Basic english ratio</th>\n",
       "      <th>Syllables per sentence</th>\n",
       "      <th>Type token ratio</th>\n",
       "      <th>#nouns</th>\n",
       "      <th>#verbs</th>\n",
       "      <th>...</th>\n",
       "      <th>Coordination</th>\n",
       "      <th>Apposition</th>\n",
       "      <th>Passive verbs</th>\n",
       "      <th>Parataxis</th>\n",
       "      <th>Auxiliary Verbs</th>\n",
       "      <th>Negation</th>\n",
       "      <th>Prepositional Phrases</th>\n",
       "      <th>Modifiers</th>\n",
       "      <th>text</th>\n",
       "      <th>embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/kea-extin...</td>\n",
       "      <td>7.687178</td>\n",
       "      <td>0.326461</td>\n",
       "      <td>0.909090</td>\n",
       "      <td>0.306252</td>\n",
       "      <td>1.298557</td>\n",
       "      <td>0.263046</td>\n",
       "      <td>0.845914</td>\n",
       "      <td>0.365935</td>\n",
       "      <td>0.465726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366106</td>\n",
       "      <td>0.201348</td>\n",
       "      <td>0.203278</td>\n",
       "      <td>0.256116</td>\n",
       "      <td>[[one, of, the, big, threat, to, the, kea, be,...</td>\n",
       "      <td>[[[2.2008598, 2.7345686, 1.5816159, -0.3842493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/australia...</td>\n",
       "      <td>16.690378</td>\n",
       "      <td>0.769983</td>\n",
       "      <td>0.995979</td>\n",
       "      <td>0.841234</td>\n",
       "      <td>1.016792</td>\n",
       "      <td>0.804812</td>\n",
       "      <td>1.071948</td>\n",
       "      <td>1.044247</td>\n",
       "      <td>0.968916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796094</td>\n",
       "      <td>1.129397</td>\n",
       "      <td>0.437070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950924</td>\n",
       "      <td>0.686415</td>\n",
       "      <td>0.712792</td>\n",
       "      <td>0.855305</td>\n",
       "      <td>[[drone, help, keep, swimmer, and, surfer, saf...</td>\n",
       "      <td>[[[1.26283, -1.055358, 1.439421, -3.4633675, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/city-trol...</td>\n",
       "      <td>8.278258</td>\n",
       "      <td>0.352503</td>\n",
       "      <td>0.955849</td>\n",
       "      <td>0.313058</td>\n",
       "      <td>1.250405</td>\n",
       "      <td>0.273918</td>\n",
       "      <td>0.879494</td>\n",
       "      <td>0.373708</td>\n",
       "      <td>0.457185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240468</td>\n",
       "      <td>0.180049</td>\n",
       "      <td>0.278712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440578</td>\n",
       "      <td>0.437714</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.306794</td>\n",
       "      <td>[[a, california, company, have, make, old, tim...</td>\n",
       "      <td>[[[2.5433478, 0.5299729, 0.8516243, -2.2341113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/parkland-...</td>\n",
       "      <td>12.440091</td>\n",
       "      <td>0.538971</td>\n",
       "      <td>0.846982</td>\n",
       "      <td>0.603712</td>\n",
       "      <td>0.943163</td>\n",
       "      <td>0.505093</td>\n",
       "      <td>0.689046</td>\n",
       "      <td>0.619676</td>\n",
       "      <td>0.733049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442461</td>\n",
       "      <td>1.325159</td>\n",
       "      <td>0.128207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496858</td>\n",
       "      <td>0.805393</td>\n",
       "      <td>0.391068</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>[[the, drama, teacher, at, the, parkland, ,, f...</td>\n",
       "      <td>[[[0.95628387, 0.83530265, 0.5133347, -2.16438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/ts_cost_function/clean_newsela/nyc-elect...</td>\n",
       "      <td>9.679800</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.947809</td>\n",
       "      <td>0.433960</td>\n",
       "      <td>1.017136</td>\n",
       "      <td>0.382856</td>\n",
       "      <td>0.848541</td>\n",
       "      <td>0.602820</td>\n",
       "      <td>0.547810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372263</td>\n",
       "      <td>0.637095</td>\n",
       "      <td>0.493105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440031</td>\n",
       "      <td>0.290406</td>\n",
       "      <td>0.379750</td>\n",
       "      <td>0.316627</td>\n",
       "      <td>[[he, be, the, first, democrat, to, be, elect,...</td>\n",
       "      <td>[[[1.6656269, -2.9132452, -0.45222923, -3.5725...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  feature_sums  \\\n",
       "0  /data/ts_cost_function/clean_newsela/kea-extin...      7.687178   \n",
       "1  /data/ts_cost_function/clean_newsela/australia...     16.690378   \n",
       "2  /data/ts_cost_function/clean_newsela/city-trol...      8.278258   \n",
       "3  /data/ts_cost_function/clean_newsela/parkland-...     12.440091   \n",
       "4  /data/ts_cost_function/clean_newsela/nyc-elect...      9.679800   \n",
       "\n",
       "   regression_score  Mean word length  Mean sentence length  \\\n",
       "0          0.326461          0.909090              0.306252   \n",
       "1          0.769983          0.995979              0.841234   \n",
       "2          0.352503          0.955849              0.313058   \n",
       "3          0.538971          0.846982              0.603712   \n",
       "4          0.476461          0.947809              0.433960   \n",
       "\n",
       "   Basic english ratio  Syllables per sentence  Type token ratio    #nouns  \\\n",
       "0             1.298557                0.263046          0.845914  0.365935   \n",
       "1             1.016792                0.804812          1.071948  1.044247   \n",
       "2             1.250405                0.273918          0.879494  0.373708   \n",
       "3             0.943163                0.505093          0.689046  0.619676   \n",
       "4             1.017136                0.382856          0.848541  0.602820   \n",
       "\n",
       "     #verbs                        ...                          Coordination  \\\n",
       "0  0.465726                        ...                              0.202795   \n",
       "1  0.968916                        ...                              0.796094   \n",
       "2  0.457185                        ...                              0.240468   \n",
       "3  0.733049                        ...                              0.442461   \n",
       "4  0.547810                        ...                              0.372263   \n",
       "\n",
       "   Apposition  Passive verbs  Parataxis  Auxiliary Verbs  Negation  \\\n",
       "0    0.000000       0.256415        0.0         0.366106  0.201348   \n",
       "1    1.129397       0.437070        0.0         0.950924  0.686415   \n",
       "2    0.180049       0.278712        0.0         0.440578  0.437714   \n",
       "3    1.325159       0.128207        0.0         0.496858  0.805393   \n",
       "4    0.637095       0.493105        0.0         0.440031  0.290406   \n",
       "\n",
       "   Prepositional Phrases  Modifiers  \\\n",
       "0               0.203278   0.256116   \n",
       "1               0.712792   0.855305   \n",
       "2               0.183076   0.306794   \n",
       "3               0.391068   0.282251   \n",
       "4               0.379750   0.316627   \n",
       "\n",
       "                                                text  \\\n",
       "0  [[one, of, the, big, threat, to, the, kea, be,...   \n",
       "1  [[drone, help, keep, swimmer, and, surfer, saf...   \n",
       "2  [[a, california, company, have, make, old, tim...   \n",
       "3  [[the, drama, teacher, at, the, parkland, ,, f...   \n",
       "4  [[he, be, the, first, democrat, to, be, elect,...   \n",
       "\n",
       "                                               embed  \n",
       "0  [[[2.2008598, 2.7345686, 1.5816159, -0.3842493...  \n",
       "1  [[[1.26283, -1.055358, 1.439421, -3.4633675, -...  \n",
       "2  [[[2.5433478, 0.5299729, 0.8516243, -2.2341113...  \n",
       "3  [[[0.95628387, 0.83530265, 0.5133347, -2.16438...  \n",
       "4  [[[1.6656269, -2.9132452, -0.45222923, -3.5725...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_texts = df.apply(lambda x: text_to_vector(lem_word2vec_model,x[\"text\"]),axis=1)\n",
    "df[\"embed\"] = vectorized_texts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use predefined word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f505dffac88>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_len = df.apply(lambda x: len(x[\"embed\"]),axis=1)\n",
    "test_len.plot.hist(bins=range(0,260,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fe34e4550>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_lens = df.apply(lambda x: [len(sent) for sent in x[\"embed\"]],axis=1)\n",
    "max_sent_len = sent_lens.apply(lambda x: np.max(x))\n",
    "max_sent_len.plot.hist(bins=range(0,260,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_padding(embed,max_sent,max_word,embed_size):\n",
    "    result = np.zeros((max_sent,max_word,embed_size))\n",
    "    for sent_ind,sent in enumerate(embed[:max_sent]):\n",
    "        for word_ind,word in enumerate(sent[:max_word]):\n",
    "            result[sent_ind,word_ind] = word\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embed_pad\"] = df.apply(\n",
    "        lambda x: embed_padding(\n",
    "            x[\"embed\"],\n",
    "            100,\n",
    "            100,\n",
    "            50),\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('/data/ts_cost_function/embed_pad.npy', df[\"embed_pad\"])\n",
    "#Result: Memory Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays = np.stack(df[\"embed_pad\"].values)\n",
    "#Result: Memory Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_word_embed_input_fn(df,batch_size,epochs):\n",
    "\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        df[[\"#nouns\"]],\n",
    "        y=df[\"regression_score\"],\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=epochs,\n",
    "        shuffle=False,\n",
    "        queue_capacity=1000,\n",
    "        num_threads=1,\n",
    "        target_column=\"regression_score\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InternalError'>, Unable to get element as bytes.\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_29_enqueue_input_9/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: fifo_queue_DequeueUpTo_3 = QueueDequeueUpToV2[component_types=[DT_INT64, DT_DOUBLE, DT_DOUBLE], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](enqueue_input_9/fifo_queue, fifo_queue_DequeueUpTo_3/n)]]\n\nCaused by op 'fifo_queue_DequeueUpTo_3', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-8da7294b7876>\", line 2, in <module>\n    features_op, labels_op = func()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/pandas_io.py\", line 114, in input_fn\n    features = queue.dequeue_up_to(batch_size)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 527, in dequeue_up_to\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3644, in queue_dequeue_up_to_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): FIFOQueue '_29_enqueue_input_9/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: fifo_queue_DequeueUpTo_3 = QueueDequeueUpToV2[component_types=[DT_INT64, DT_DOUBLE, DT_DOUBLE], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](enqueue_input_9/fifo_queue, fifo_queue_DequeueUpTo_3/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_29_enqueue_input_9/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: fifo_queue_DequeueUpTo_3 = QueueDequeueUpToV2[component_types=[DT_INT64, DT_DOUBLE, DT_DOUBLE], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](enqueue_input_9/fifo_queue, fifo_queue_DequeueUpTo_3/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-8da7294b7876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoordinator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: FIFOQueue '_29_enqueue_input_9/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: fifo_queue_DequeueUpTo_3 = QueueDequeueUpToV2[component_types=[DT_INT64, DT_DOUBLE, DT_DOUBLE], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](enqueue_input_9/fifo_queue, fifo_queue_DequeueUpTo_3/n)]]\n\nCaused by op 'fifo_queue_DequeueUpTo_3', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-8da7294b7876>\", line 2, in <module>\n    features_op, labels_op = func()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/pandas_io.py\", line 114, in input_fn\n    features = queue.dequeue_up_to(batch_size)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 527, in dequeue_up_to\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3644, in queue_dequeue_up_to_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): FIFOQueue '_29_enqueue_input_9/fifo_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: fifo_queue_DequeueUpTo_3 = QueueDequeueUpToV2[component_types=[DT_INT64, DT_DOUBLE, DT_DOUBLE], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](enqueue_input_9/fifo_queue, fifo_queue_DequeueUpTo_3/n)]]\n"
     ]
    }
   ],
   "source": [
    "func = define_word_embed_input_fn(df,10,1)\n",
    "features_op, labels_op = func()\n",
    "with tf.Session() as sess:\n",
    "    # initialise and start the queues.\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    coordinator = tf.train.Coordinator()\n",
    "    _ = tf.train.start_queue_runners(coord=coordinator)\n",
    "\n",
    "    print(sess.run([features_op, labels_op]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embed_generator(df):\n",
    "    for ind,row in df.iterrows():\n",
    "        yield (row[\"embed_pad\"],row[\"regression_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 5)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((5,5))\n",
    "b = np.zeros((5,5))\n",
    "c = np.zeros((5,5))\n",
    "np.stack([a,b,c]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word_emb_fn(df,batch_size,max_sent,max_word,embed_size):\n",
    "    \n",
    "    #dataset = tf.data.Dataset.from_tensor_slices((dict(df[\"embed_pad\"]), df[\"regression_score\"]))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: \n",
    "                                             word_embed_generator(df), \n",
    "                                             (tf.float64, tf.float64), \n",
    "                                             (tf.TensorShape([max_sent,max_word,embed_size]),\n",
    "                                             tf.TensorShape([])))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.repeat().batch(batch_size)#.shuffle(1000).repeat().batch(batch_size)\n",
    "    #shuffle(1000)\n",
    "    \n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_word_emb_fn(df,10,100,100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "result = sess.run(dataset_iter.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 100, 50)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_word_emb_fn(features, labels=None, batch_size=None):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert inputs to a tf.dataset object.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding + Sentence RNN + Text RNN\n",
    "\n",
    "The sentence RNN will output a hidden state for each sentence. Afterwards each hidden state will be used as a input for another RNN on text level. The final output is than the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 100, 50)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 21, 45, 73, 53, 52, 47, 29, 95, 41])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "#word_mask = sess.run(tf.reduce_max(tf.count_nonzero(tf.reshape(result[0],[1000,100,50]), 1),1))\n",
    "sent_mask = sess.run(tf.count_nonzero(tf.reduce_max(tf.count_nonzero(result[0], 2),2), 1))\n",
    "\n",
    "sent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_emb_rnn_rnn_fn(features, labels, mode):\n",
    "    \n",
    "    \n",
    "    #word_mask = tf.reduce_max(tf.count_nonzero(result[0], 2),2)\n",
    "    word_mask = tf.reduce_max(tf.count_nonzero(tf.reshape(features,[1000,100,50]), 1),1)\n",
    "    #sent_mask = tf.count_nonzero(word_mask, 1)\n",
    "    sent_mask = tf.count_nonzero(tf.reduce_max(tf.count_nonzero(result[0], 2),2), 1)\n",
    "\n",
    "    concat_sents = tf.reshape(features,[1000,100,50])\n",
    "    \n",
    "    #init_state = tf.cells.zero_state(batch_size, tf.float32)\n",
    "    with tf.variable_scope('word_cell'):\n",
    "        word_cell = tf.contrib.rnn.BasicLSTMCell(num_units=64, state_is_tuple=True)\n",
    "        word_outputs, word_last_states = tf.nn.dynamic_rnn(\n",
    "            cell=word_cell,\n",
    "            dtype=tf.float64,\n",
    "            sequence_length=word_mask,\n",
    "            #initial_state=init_state,\n",
    "            inputs=concat_sents)\n",
    "        \n",
    "        reshaped_word_last_states = tf.reshape(word_last_states.c,[10,100,64])\n",
    "        \n",
    "    with tf.variable_scope('sent_cell'):\n",
    "        sent_cell = tf.contrib.rnn.BasicLSTMCell(num_units=64, state_is_tuple=False)\n",
    "        sent_outputs, sent_last_states = tf.nn.dynamic_rnn(\n",
    "            cell=sent_cell,\n",
    "            dtype=tf.float64,\n",
    "            sequence_length=sent_mask,\n",
    "            inputs=reshaped_word_last_states)\n",
    "    \n",
    "    #text_output = tf.contrib.layers.fully_connected(sent_last_states,1)\n",
    "    pred_value = tf.layers.dense(inputs=sent_last_states, units=1, activation=None)\n",
    "    \n",
    "    reshaped_labels = tf.reshape(labels,[10,1])\n",
    "    \n",
    "    cost = tf.losses.mean_squared_error(reshaped_labels,pred_value)\n",
    "    \n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"logits\": pred_value,\n",
    "        \"loss\":cost\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=cost,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, \n",
    "            loss=cost,\n",
    "            train_op=train_op)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding + Conv + RNN\n",
    "\n",
    "Taghipour, Kaveh, and Hwee Tou Ng. \"A neural approach to automated essay scoring.\" Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](A_Neural_Approach_to_Automated_Essay_Scoring.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimator\n",
    "\n",
    "## 1D Conv Layer for Text Embedding\n",
    "\n",
    "\n",
    "## Recurrent Layer with each Conv Layer Output as Input\n",
    "## Output: Score\n",
    "\n",
    "## Mean over time of all RNN scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_task_type': 'worker', '_master': '', '_train_distribute': None, '_service': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_session_config': None, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_model_dir': '/data/ts_cost_function/model_emb_rnn_rnn', '_num_ps_replicas': 0, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f35202931d0>, '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model_emb_rnn_rnn = tf.estimator.Estimator(\n",
    "    model_fn=model_emb_rnn_rnn_fn, model_dir=\"/data/ts_cost_function/model_emb_rnn_rnn\")\n",
    "\n",
    "\n",
    "#tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "#logging_hook = tf.train.LoggingTensorHook(\n",
    "#  tensors=tensors_to_log, every_n_iter=2000)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f3520143ba8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /data/ts_cost_function/model_emb_rnn_rnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.1952132, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /data/ts_cost_function/model_emb_rnn_rnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.101836614.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f35201e65c0>"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_emb_rnn_rnn.train(\n",
    "    input_fn=lambda:train_word_emb_fn(\n",
    "        df,10,100,100,50),\n",
    "    steps=10,)\n",
    "    #hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_4:0' shape=(10, 100, 64) dtype=float64>"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(word_last_states.c,[10,100,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = mnist_classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(X_test,y_test,len(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
