{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as kr\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 10.0)) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31958"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import training and test set\n",
    "df = pd.read_csv(\"data/training_data.csv\",sep=\";\")\n",
    "df = df.loc[df[\"text\"] != \"LSAT\"]\n",
    "df = df.loc[df[\"path\"] != \"LSAT\"]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#adjectives</th>\n",
       "      <th>#adverbs</th>\n",
       "      <th>#commas</th>\n",
       "      <th>#nouns</th>\n",
       "      <th>#pronouns</th>\n",
       "      <th>#verbs</th>\n",
       "      <th>Apposition</th>\n",
       "      <th>Auxiliary Verbs</th>\n",
       "      <th>Basic english ratio</th>\n",
       "      <th>Complements</th>\n",
       "      <th>...</th>\n",
       "      <th>Prepositional Phrases</th>\n",
       "      <th>Subordination</th>\n",
       "      <th>Syllables per sentence</th>\n",
       "      <th>Type token ratio</th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_sums</th>\n",
       "      <th>newsela_score</th>\n",
       "      <th>path</th>\n",
       "      <th>regression_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [#adjectives, #adverbs, #commas, #nouns, #pronouns, #verbs, Apposition, Auxiliary Verbs, Basic english ratio, Complements, Coordination, Mean sentence length, Mean word length, Modifiers, Negation, Parataxis, Passive verbs, Prepositional Phrases, Subordination, Syllables per sentence, Type token ratio, dataset, feature_sums, newsela_score, path, regression_score, text]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"text\"] == \"LSAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_text(dic):\n",
    "    if dic[\"dataset\"] == \"newsela\":\n",
    "        path = \"data/newsela/\"+\"-\".join(\n",
    "            [dic[\"path\"],\n",
    "             dic[\"text\"],\n",
    "             str(roundup(int(dic[\"newsela_score\"])))])+\".txt\"\n",
    "    else:\n",
    "        path = dic[\"path\"]+\"/\"+dic[\"text\"]\n",
    "    with open(path,\"r\") as f:\n",
    "        text =  f.read()\n",
    "        text = text.replace(\"\\n\",\"\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = df.columns[:-6]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "12it [00:00, 115.49it/s]\u001b[A\n",
      "28it [00:00, 136.96it/s]\u001b[A\n",
      "44it [00:00, 142.18it/s]\u001b[A\n",
      "61it [00:00, 147.69it/s]\u001b[A\n",
      "79it [00:00, 153.46it/s]\u001b[A\n",
      "95it [00:00, 153.58it/s]\u001b[A\n",
      "113it [00:00, 156.42it/s]\u001b[A\n",
      "130it [00:00, 157.24it/s]\u001b[A\n",
      "146it [00:00, 156.45it/s]\u001b[A\n",
      "164it [00:01, 158.02it/s]\u001b[A\n",
      "181it [00:01, 158.87it/s]\u001b[A\n",
      "198it [00:01, 159.29it/s]\u001b[A\n",
      "217it [00:01, 160.57it/s]\u001b[A\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/d062280/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/d062280/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/d062280/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "29061it [02:25, 199.07it/s]\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd1 in position 322: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-ab0f9d7c85f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mword_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_file_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-99-3d8cf099f7ff>\u001b[0m in \u001b[0;36mget_file_text\u001b[0;34m(dic)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd1 in position 322: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "word_set = set()\n",
    "for ind,row in tqdm(df.iterrows()):\n",
    "    word_set.update(word_tokenize(get_file_text(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#adjectives</th>\n",
       "      <th>#adverbs</th>\n",
       "      <th>#commas</th>\n",
       "      <th>#nouns</th>\n",
       "      <th>#pronouns</th>\n",
       "      <th>#verbs</th>\n",
       "      <th>Apposition</th>\n",
       "      <th>Auxiliary Verbs</th>\n",
       "      <th>Basic english ratio</th>\n",
       "      <th>Complements</th>\n",
       "      <th>...</th>\n",
       "      <th>Prepositional Phrases</th>\n",
       "      <th>Subordination</th>\n",
       "      <th>Syllables per sentence</th>\n",
       "      <th>Type token ratio</th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_sums</th>\n",
       "      <th>newsela_score</th>\n",
       "      <th>path</th>\n",
       "      <th>regression_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21461</th>\n",
       "      <td>0.258485</td>\n",
       "      <td>0.245187</td>\n",
       "      <td>0.238623</td>\n",
       "      <td>0.652328</td>\n",
       "      <td>0.590439</td>\n",
       "      <td>0.645025</td>\n",
       "      <td>0.224318</td>\n",
       "      <td>0.353179</td>\n",
       "      <td>0.403829</td>\n",
       "      <td>0.468977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267001</td>\n",
       "      <td>0.337274</td>\n",
       "      <td>0.445774</td>\n",
       "      <td>2.073733</td>\n",
       "      <td>newsela</td>\n",
       "      <td>10.983150</td>\n",
       "      <td>810.0</td>\n",
       "      <td>girls-code</td>\n",
       "      <td>0.417919</td>\n",
       "      <td>26751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21462</th>\n",
       "      <td>0.712513</td>\n",
       "      <td>0.522254</td>\n",
       "      <td>0.748760</td>\n",
       "      <td>1.076711</td>\n",
       "      <td>0.405278</td>\n",
       "      <td>0.682222</td>\n",
       "      <td>1.250424</td>\n",
       "      <td>0.322156</td>\n",
       "      <td>0.489988</td>\n",
       "      <td>0.516647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370098</td>\n",
       "      <td>0.379813</td>\n",
       "      <td>0.728327</td>\n",
       "      <td>2.109417</td>\n",
       "      <td>newsela</td>\n",
       "      <td>14.735500</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>football-stadiums-texas</td>\n",
       "      <td>0.619383</td>\n",
       "      <td>22080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21463</th>\n",
       "      <td>0.433646</td>\n",
       "      <td>0.621203</td>\n",
       "      <td>0.485932</td>\n",
       "      <td>0.768370</td>\n",
       "      <td>0.965060</td>\n",
       "      <td>0.729235</td>\n",
       "      <td>0.793580</td>\n",
       "      <td>0.362341</td>\n",
       "      <td>0.443175</td>\n",
       "      <td>0.894481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472290</td>\n",
       "      <td>0.424244</td>\n",
       "      <td>0.599995</td>\n",
       "      <td>2.258061</td>\n",
       "      <td>newsela</td>\n",
       "      <td>13.484169</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>shooting-florida-highschool</td>\n",
       "      <td>0.574471</td>\n",
       "      <td>40560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21464</th>\n",
       "      <td>0.670964</td>\n",
       "      <td>0.797932</td>\n",
       "      <td>0.549870</td>\n",
       "      <td>0.810773</td>\n",
       "      <td>0.358047</td>\n",
       "      <td>0.570806</td>\n",
       "      <td>0.764722</td>\n",
       "      <td>0.436456</td>\n",
       "      <td>0.480899</td>\n",
       "      <td>1.077443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408266</td>\n",
       "      <td>0.212926</td>\n",
       "      <td>0.604981</td>\n",
       "      <td>2.289819</td>\n",
       "      <td>newsela</td>\n",
       "      <td>13.180524</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>global-warming-exercise</td>\n",
       "      <td>0.584063</td>\n",
       "      <td>29877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21465</th>\n",
       "      <td>0.206819</td>\n",
       "      <td>0.298192</td>\n",
       "      <td>0.191259</td>\n",
       "      <td>0.430349</td>\n",
       "      <td>0.576766</td>\n",
       "      <td>0.461285</td>\n",
       "      <td>0.485304</td>\n",
       "      <td>0.305635</td>\n",
       "      <td>0.405473</td>\n",
       "      <td>0.470546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226528</td>\n",
       "      <td>0.216201</td>\n",
       "      <td>0.328882</td>\n",
       "      <td>2.372436</td>\n",
       "      <td>newsela</td>\n",
       "      <td>11.000254</td>\n",
       "      <td>600.0</td>\n",
       "      <td>hatchimals-lawsuit</td>\n",
       "      <td>0.336211</td>\n",
       "      <td>26119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21466</th>\n",
       "      <td>0.711022</td>\n",
       "      <td>0.531955</td>\n",
       "      <td>0.752454</td>\n",
       "      <td>1.228999</td>\n",
       "      <td>0.483363</td>\n",
       "      <td>0.856210</td>\n",
       "      <td>0.862763</td>\n",
       "      <td>0.764088</td>\n",
       "      <td>0.473603</td>\n",
       "      <td>1.294001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928766</td>\n",
       "      <td>0.720671</td>\n",
       "      <td>0.919316</td>\n",
       "      <td>2.102172</td>\n",
       "      <td>newsela</td>\n",
       "      <td>17.624290</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>meat-antibiotics</td>\n",
       "      <td>0.841941</td>\n",
       "      <td>36181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21467</th>\n",
       "      <td>0.432146</td>\n",
       "      <td>0.538395</td>\n",
       "      <td>0.354154</td>\n",
       "      <td>0.607256</td>\n",
       "      <td>0.368970</td>\n",
       "      <td>0.631378</td>\n",
       "      <td>0.576160</td>\n",
       "      <td>0.390069</td>\n",
       "      <td>0.428534</td>\n",
       "      <td>0.586571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270283</td>\n",
       "      <td>0.359348</td>\n",
       "      <td>0.490503</td>\n",
       "      <td>2.344178</td>\n",
       "      <td>newsela</td>\n",
       "      <td>13.200059</td>\n",
       "      <td>850.0</td>\n",
       "      <td>china-gifts</td>\n",
       "      <td>0.466307</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>0.528106</td>\n",
       "      <td>0.383070</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.679974</td>\n",
       "      <td>0.596988</td>\n",
       "      <td>0.635130</td>\n",
       "      <td>0.841194</td>\n",
       "      <td>0.437058</td>\n",
       "      <td>0.484422</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429951</td>\n",
       "      <td>0.430961</td>\n",
       "      <td>0.559238</td>\n",
       "      <td>2.281008</td>\n",
       "      <td>newsela</td>\n",
       "      <td>13.166159</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>students-3D-printing</td>\n",
       "      <td>0.548758</td>\n",
       "      <td>29735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21469</th>\n",
       "      <td>0.398668</td>\n",
       "      <td>0.635994</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.557635</td>\n",
       "      <td>1.101419</td>\n",
       "      <td>0.808347</td>\n",
       "      <td>0.525746</td>\n",
       "      <td>0.524249</td>\n",
       "      <td>0.419620</td>\n",
       "      <td>1.242535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392649</td>\n",
       "      <td>0.429400</td>\n",
       "      <td>0.542658</td>\n",
       "      <td>1.953912</td>\n",
       "      <td>newsela</td>\n",
       "      <td>18.787521</td>\n",
       "      <td>950.0</td>\n",
       "      <td>camnewton-quarterback</td>\n",
       "      <td>0.513944</td>\n",
       "      <td>14811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>0.439093</td>\n",
       "      <td>0.541454</td>\n",
       "      <td>0.264361</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>0.470969</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.458833</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.457435</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471179</td>\n",
       "      <td>0.425851</td>\n",
       "      <td>0.569622</td>\n",
       "      <td>2.050762</td>\n",
       "      <td>newsela</td>\n",
       "      <td>13.252552</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>looted-art</td>\n",
       "      <td>0.562819</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #adjectives  #adverbs   #commas    #nouns  #pronouns    #verbs  \\\n",
       "21461     0.258485  0.245187  0.238623  0.652328   0.590439  0.645025   \n",
       "21462     0.712513  0.522254  0.748760  1.076711   0.405278  0.682222   \n",
       "21463     0.433646  0.621203  0.485932  0.768370   0.965060  0.729235   \n",
       "21464     0.670964  0.797932  0.549870  0.810773   0.358047  0.570806   \n",
       "21465     0.206819  0.298192  0.191259  0.430349   0.576766  0.461285   \n",
       "21466     0.711022  0.531955  0.752454  1.228999   0.483363  0.856210   \n",
       "21467     0.432146  0.538395  0.354154  0.607256   0.368970  0.631378   \n",
       "21468     0.528106  0.383070  0.516205  0.679974   0.596988  0.635130   \n",
       "21469     0.398668  0.635994  0.589147  0.557635   1.101419  0.808347   \n",
       "21470     0.439093  0.541454  0.264361  0.680959   0.470969  0.770779   \n",
       "\n",
       "       Apposition  Auxiliary Verbs  Basic english ratio  Complements  ...    \\\n",
       "21461    0.224318         0.353179             0.403829     0.468977  ...     \n",
       "21462    1.250424         0.322156             0.489988     0.516647  ...     \n",
       "21463    0.793580         0.362341             0.443175     0.894481  ...     \n",
       "21464    0.764722         0.436456             0.480899     1.077443  ...     \n",
       "21465    0.485304         0.305635             0.405473     0.470546  ...     \n",
       "21466    0.862763         0.764088             0.473603     1.294001  ...     \n",
       "21467    0.576160         0.390069             0.428534     0.586571  ...     \n",
       "21468    0.841194         0.437058             0.484422     0.795222  ...     \n",
       "21469    0.525746         0.524249             0.419620     1.242535  ...     \n",
       "21470    0.458833         0.746491             0.457435     0.778539  ...     \n",
       "\n",
       "       Prepositional Phrases  Subordination  Syllables per sentence  \\\n",
       "21461               0.267001       0.337274                0.445774   \n",
       "21462               0.370098       0.379813                0.728327   \n",
       "21463               0.472290       0.424244                0.599995   \n",
       "21464               0.408266       0.212926                0.604981   \n",
       "21465               0.226528       0.216201                0.328882   \n",
       "21466               0.928766       0.720671                0.919316   \n",
       "21467               0.270283       0.359348                0.490503   \n",
       "21468               0.429951       0.430961                0.559238   \n",
       "21469               0.392649       0.429400                0.542658   \n",
       "21470               0.471179       0.425851                0.569622   \n",
       "\n",
       "       Type token ratio  dataset  feature_sums  newsela_score  \\\n",
       "21461          2.073733  newsela     10.983150          810.0   \n",
       "21462          2.109417  newsela     14.735500         1120.0   \n",
       "21463          2.258061  newsela     13.484169         1050.0   \n",
       "21464          2.289819  newsela     13.180524         1030.0   \n",
       "21465          2.372436  newsela     11.000254          600.0   \n",
       "21466          2.102172  newsela     17.624290         1440.0   \n",
       "21467          2.344178  newsela     13.200059          850.0   \n",
       "21468          2.281008  newsela     13.166159         1030.0   \n",
       "21469          1.953912  newsela     18.787521          950.0   \n",
       "21470          2.050762  newsela     13.252552         1000.0   \n",
       "\n",
       "                              path  regression_score   text  \n",
       "21461                   girls-code          0.417919  26751  \n",
       "21462      football-stadiums-texas          0.619383  22080  \n",
       "21463  shooting-florida-highschool          0.574471  40560  \n",
       "21464      global-warming-exercise          0.584063  29877  \n",
       "21465           hatchimals-lawsuit          0.336211  26119  \n",
       "21466             meat-antibiotics          0.841941  36181  \n",
       "21467                  china-gifts          0.466307   1450  \n",
       "21468         students-3D-printing          0.548758  29735  \n",
       "21469        camnewton-quarterback          0.513944  14811  \n",
       "21470                   looted-art          0.562819   1641  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[21460:21470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"data/weebit/WeeBit-TextOnly/BitGCSE/3644.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
