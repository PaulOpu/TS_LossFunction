{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build score dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./data/newsela/lemma.num\")\n",
    "\n",
    "word_scores = {}\n",
    "\n",
    "for line in f:\n",
    "    word = line.split()[2]\n",
    "    rank = int(line.split()[0])\n",
    "    \n",
    "    # words may occur multiple times (for example \"to\" as preposition and infitive marker)\n",
    "    # in these cases, keep only lowest score\n",
    "    if not word in word_scores:\n",
    "        word_scores[word] = np.log(rank)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 0.0\n",
      "of: 1.0986122886681098\n",
      "it: 2.1972245773362196\n",
      "she: 3.332204510175204\n",
      "far: 5.84354441703136\n",
      "severe: 7.578656850594762\n",
      "fiscal: 8.456806041401142\n",
      "linen: 8.625329850020815\n",
      "antidisestablishmentarianism: 9.0\n"
     ]
    }
   ],
   "source": [
    "# use .get() to return default value if key not in dictionary\n",
    "for w in [\"the\", \"of\", \"it\", \"she\", \"far\", \"severe\", \"fiscal\", \"linen\", \"antidisestablishmentarianism\"]:\n",
    "    print(\"{}: {}\".format(w, word_scores.get(w, 9.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score newsela article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsela_dir = \"./data/newsela/42157-\"\n",
    "newsela_levels = [\"560\", \"830\", \"920\", \"1020\", \"max\"]\n",
    "\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "punc = [\".\", \",\", \"!\", \"?\", \"(\", \")\", \"``\", \"''\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average word difficulty scores:\n",
      "level  560:  4.7132 (0.124% of words unknown)\n",
      "level  830:  4.8617 (0.139% of words unknown)\n",
      "level  920:  4.8521 (0.130% of words unknown)\n",
      "level 1020:  4.9233 (0.147% of words unknown)\n",
      "level  max:  5.0566 (0.179% of words unknown)\n"
     ]
    }
   ],
   "source": [
    "print(\"average word difficulty scores:\")\n",
    "for level in newsela_levels:\n",
    "    f = open(newsela_dir + level + \".txt\")\n",
    "    score = 0\n",
    "    num_words = 0\n",
    "    unknown = 0\n",
    "    \n",
    "    for line in f:\n",
    "        # tokenize and POS-tag every line in the file\n",
    "        for w, t in nltk.pos_tag(nltk.word_tokenize(line)):\n",
    "            # ignore punctuation\n",
    "            if w not in punc:\n",
    "                # extract POS for correct lemmatization\n",
    "                tag = t[0].lower()\n",
    "                tag = tag if tag in [\"n\", \"v\", \"j\", \"r\"] else None\n",
    "                tag = \"a\" if tag == \"j\" else tag\n",
    "                \n",
    "                if not tag:\n",
    "                    w = lem.lemmatize(w.lower())\n",
    "                else:\n",
    "                    w = lem.lemmatize(w.lower(), tag)\n",
    "                \n",
    "                # add word difficulty score to total\n",
    "                num_words += 1\n",
    "                if w not in word_scores:\n",
    "                    unknown += 1\n",
    "                score += word_scores.get(w, 9)\n",
    "                \n",
    "                #print unknown words:\n",
    "                #if word_scores.get(w, 9.) == 9.:\n",
    "                #    print(\"{:15} {:4} {} {:.4f}\".format(w, t, \" \" if not tag else tag, word_scores.get(w, 9.)))\n",
    "    \n",
    "    # calculate average difficulty score and percentage of unknown words\n",
    "    score = score / num_words\n",
    "    unknown = unknown / num_words\n",
    "    \n",
    "    print(\"level {:>4}:  {:.4f} ({:.3f}% of words unknown)\".format(level, score, unknown))\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unknown words for ...560.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'s              POS    9.0000\n",
    "deeper          NN   n 9.0000\n",
    "darker          NN   n 9.0000\n",
    "colder          VB   v 9.0000\n",
    "others          NNS  n 9.0000\n",
    "john            NNP  n 9.0000\n",
    "spark           NNP  n 9.0000\n",
    "american        NNP  n 9.0000\n",
    "york            NNP  n 9.0000\n",
    "glue            NNP  n 9.0000\n",
    "jellyfish       NNP  n 9.0000\n",
    "kakani          NNP  n 9.0000\n",
    "katija          NNP  n 9.0000\n",
    "monterey        NNP  n 9.0000\n",
    "california      NNP  n 9.0000\n",
    "jellyfish       NN   n 9.0000\n",
    "katija          NNP  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "jellyfish       NN   n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "tag             JJ   a 9.0000\n",
    "katija          NNP  n 9.0000\n",
    "others          NNS  n 9.0000\n",
    "tag             NN   n 9.0000\n",
    "katija          NNP  n 9.0000\n",
    "others          NNS  n 9.0000\n",
    "katija          NNP  n 9.0000\n",
    "'s              POS    9.0000\n",
    "backpack        NN   n 9.0000\n",
    "glue            NN   n 9.0000\n",
    "hike            VBG  v 9.0000\n",
    "glue            NN   n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "jellyfish       NN   n 9.0000\n",
    "glue            NN   n 9.0000\n",
    "tag             NN   n 9.0000\n",
    "mini            NNP  n 9.0000\n",
    "robot           NNP  n 9.0000\n",
    "plankton        NNP  n 9.0000\n",
    "plankton        NNP  n 9.0000\n",
    "jules           NNS  n 9.0000\n",
    "jaffe           NNP  n 9.0000\n",
    "scripps         NNP  n 9.0000\n",
    "oceanography    NNP  n 9.0000\n",
    "san             NNP  n 9.0000\n",
    "diego           NNP  n 9.0000\n",
    "california      NNP  n 9.0000\n",
    "plankton        JJ   a 9.0000\n",
    "jaffe           NNP  n 9.0000\n",
    "mini-underwater JJ   a 9.0000\n",
    "robot           NNS  n 9.0000\n",
    "plankton        NN   n 9.0000\n",
    "two             CD     9.0000\n",
    "jaffe           NNP  n 9.0000\n",
    "two             CD     9.0000\n",
    "jeremy          NNP  n 9.0000\n",
    "goldbogen       NNP  n 9.0000\n",
    "stanford        NNP  n 9.0000\n",
    "'s              POS    9.0000\n",
    "hopkins         NNP  n 9.0000\n",
    "california      NNP  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "suction         NN   n 9.0000\n",
    "tag             NNS  n 9.0000\n",
    "underwater      JJ   a 9.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proper nouns (katija, california, monterey), wrongly tagged (deeper, darker as NN; colder as VB), number words, possessive 's "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
