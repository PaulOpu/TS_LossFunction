{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_data\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "import pyphen\n",
    "dic = pyphen.Pyphen(lang='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "british_council_path = \"data/british_council/cleaned_articles.csv\"\n",
    "tok_pos_path = \"data/british_council/tok_pos_articles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_col = \"level1\"\n",
    "level2_col = \"level2\"\n",
    "level3_col = \"level3\"\n",
    "all_level_col = [level1_col,level2_col,level3_col]\n",
    "\n",
    "level1_pos_col = \"level1_pos\"\n",
    "level2_pos_col = \"level2_pos\"\n",
    "level3_pos_col = \"level3_pos\"\n",
    "all_level_pos_col = [level1_pos_col,level2_pos_col,level3_pos_col]\n",
    "\n",
    "level1_tok_col = \"level1_tok\"\n",
    "level2_tok_col = \"level2_tok\"\n",
    "level3_tok_col = \"level3_tok\"\n",
    "all_level_tok_col = [level1_tok_col,level2_tok_col,level3_tok_col]\n",
    "\n",
    "level1_lem_col = \"level1_lem\"\n",
    "level2_lem_col = \"level2_lem\"\n",
    "level3_lem_col = \"level3_lem\"\n",
    "all_level_lem_col = [level1_lem_col,level2_lem_col,level3_lem_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walk-forest-level</td>\n",
       "      <td>[Going through the forest is my favourite part...</td>\n",
       "      <td>[Going through the forest is my favourite part...</td>\n",
       "      <td>[Going through the forest is my favourite part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazing-adventurers-level</td>\n",
       "      <td>[Do you ever dream about climbing Mount Everes...</td>\n",
       "      <td>[Have you ever dreamt of climbing Mount Everes...</td>\n",
       "      <td>[Have you ever dreamt of climbing Mount Everes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animals-city-level</td>\n",
       "      <td>[One night in December 2011, a bear came into ...</td>\n",
       "      <td>[Recently, there have been many reports in new...</td>\n",
       "      <td>[Small animals like birds, squirrels, mice and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bully-level</td>\n",
       "      <td>[Kay got another message as she was leaving fo...</td>\n",
       "      <td>[Kay got another message as she was leaving fo...</td>\n",
       "      <td>[Kay got another message as she was leaving fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheat-level</td>\n",
       "      <td>[Mo was waiting outside her class. She was fee...</td>\n",
       "      <td>[Mo was waiting in the corridor outside her cl...</td>\n",
       "      <td>[Mo was waiting in the corridor with her class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                article_name  \\\n",
       "0          walk-forest-level   \n",
       "1  amazing-adventurers-level   \n",
       "2         animals-city-level   \n",
       "3                bully-level   \n",
       "4                cheat-level   \n",
       "\n",
       "                                              level1  \\\n",
       "0  [Going through the forest is my favourite part...   \n",
       "1  [Do you ever dream about climbing Mount Everes...   \n",
       "2  [One night in December 2011, a bear came into ...   \n",
       "3  [Kay got another message as she was leaving fo...   \n",
       "4  [Mo was waiting outside her class. She was fee...   \n",
       "\n",
       "                                              level2  \\\n",
       "0  [Going through the forest is my favourite part...   \n",
       "1  [Have you ever dreamt of climbing Mount Everes...   \n",
       "2  [Recently, there have been many reports in new...   \n",
       "3  [Kay got another message as she was leaving fo...   \n",
       "4  [Mo was waiting in the corridor outside her cl...   \n",
       "\n",
       "                                              level3  \n",
       "0  [Going through the forest is my favourite part...  \n",
       "1  [Have you ever dreamt of climbing Mount Everes...  \n",
       "2  [Small animals like birds, squirrels, mice and...  \n",
       "3  [Kay got another message as she was leaving fo...  \n",
       "4  [Mo was waiting in the corridor with her class...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare_data.load_df(british_council_path,[\"cleaned1\",\"cleaned2\",\"cleaned3\"])\n",
    "df.rename(\n",
    "    index=str,\n",
    "    columns={\n",
    "        \"cleaned1\":level1_col,\n",
    "        \"cleaned2\":level2_col,\n",
    "        \"cleaned3\":level3_col},\n",
    "    inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate articles to have one 3 texts per article\n",
    "concat_df = df.copy()\n",
    "concat_df[all_level_col] = concat_df[all_level_col].applymap(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_pos_tagging(text):\n",
    "    \n",
    "    tok_text = [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text)]\n",
    "    tok_pos_text = list(zip(*[list(zip(*nltk.pos_tag(sent))) for sent in tok_text]))\n",
    "    \n",
    "    return tok_pos_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serie_tok_pos_tagging(series):\n",
    "    return [tok_pos_tagging(text) for text in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_pos_df = pd.concat([pd.DataFrame(\n",
    "        data=serie_tok_pos_tagging(concat_df[level]),\n",
    "        columns=[level+\"_tok\",level+\"_pos\"]) \n",
    " for level in all_level_col],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level1_tok</th>\n",
       "      <th>level1_pos</th>\n",
       "      <th>level2_tok</th>\n",
       "      <th>level2_pos</th>\n",
       "      <th>level3_tok</th>\n",
       "      <th>level3_pos</th>\n",
       "      <th>article_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((Going, through, the, forest, is, my, favouri...</td>\n",
       "      <td>((VBG, IN, DT, NN, VBZ, PRP$, JJ, NN, IN, DT, ...</td>\n",
       "      <td>((Going, through, the, forest, is, my, favouri...</td>\n",
       "      <td>((VBG, IN, DT, NN, VBZ, PRP$, JJ, NN, IN, DT, ...</td>\n",
       "      <td>((Going, through, the, forest, is, my, favouri...</td>\n",
       "      <td>((VBG, IN, DT, NN, VBZ, PRP$, JJ, NN, IN, DT, ...</td>\n",
       "      <td>walk-forest-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((Do, you, ever, dream, about, climbing, Mount...</td>\n",
       "      <td>((VB, PRP, RB, VBP, IN, VBG, NNP, NNP, CC, VBG...</td>\n",
       "      <td>((Have, you, ever, dreamt, of, climbing, Mount...</td>\n",
       "      <td>((VBP, PRP, RB, VB, IN, VBG, NNP, NNP, CC, VBG...</td>\n",
       "      <td>((Have, you, ever, dreamt, of, climbing, Mount...</td>\n",
       "      <td>((VBP, PRP, RB, VB, IN, VBG, NNP, NNP, CC, VBG...</td>\n",
       "      <td>amazing-adventurers-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((One, night, in, December, 2011, ,, a, bear, ...</td>\n",
       "      <td>((CD, NN, IN, NNP, CD, ,, DT, NN, VBD, IN, DT,...</td>\n",
       "      <td>((Recently, ,, there, have, been, many, report...</td>\n",
       "      <td>((RB, ,, EX, VBP, VBN, JJ, NNS, IN, NNS, CC, I...</td>\n",
       "      <td>((Small, animals, like, birds, ,, squirrels, ,...</td>\n",
       "      <td>((JJ, NNS, IN, NNS, ,, NNS, ,, NN, CC, NNS, VB...</td>\n",
       "      <td>animals-city-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((Kay, got, another, message, as, she, was, le...</td>\n",
       "      <td>((NNP, VBD, DT, NN, IN, PRP, VBD, VBG, IN, NN,...</td>\n",
       "      <td>((Kay, got, another, message, as, she, was, le...</td>\n",
       "      <td>((NNP, VBD, DT, NN, IN, PRP, VBD, VBG, IN, NN,...</td>\n",
       "      <td>((Kay, got, another, message, as, she, was, le...</td>\n",
       "      <td>((NNP, VBD, DT, NN, IN, PRP, VBD, VBG, IN, NN,...</td>\n",
       "      <td>bully-level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((Mo, was, waiting, outside, her, class, .), (...</td>\n",
       "      <td>((NNP, VBD, VBG, IN, PRP$, NN, .), (PRP, VBD, ...</td>\n",
       "      <td>((Mo, was, waiting, in, the, corridor, outside...</td>\n",
       "      <td>((NNP, VBD, VBG, IN, DT, NN, IN, PRP$, NN, .),...</td>\n",
       "      <td>((Mo, was, waiting, in, the, corridor, with, h...</td>\n",
       "      <td>((NNP, VBD, VBG, IN, DT, NN, IN, PRP$, NN, IN,...</td>\n",
       "      <td>cheat-level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          level1_tok  \\\n",
       "0  ((Going, through, the, forest, is, my, favouri...   \n",
       "1  ((Do, you, ever, dream, about, climbing, Mount...   \n",
       "2  ((One, night, in, December, 2011, ,, a, bear, ...   \n",
       "3  ((Kay, got, another, message, as, she, was, le...   \n",
       "4  ((Mo, was, waiting, outside, her, class, .), (...   \n",
       "\n",
       "                                          level1_pos  \\\n",
       "0  ((VBG, IN, DT, NN, VBZ, PRP$, JJ, NN, IN, DT, ...   \n",
       "1  ((VB, PRP, RB, VBP, IN, VBG, NNP, NNP, CC, VBG...   \n",
       "2  ((CD, NN, IN, NNP, CD, ,, DT, NN, VBD, IN, DT,...   \n",
       "3  ((NNP, VBD, DT, NN, IN, PRP, VBD, VBG, IN, NN,...   \n",
       "4  ((NNP, VBD, VBG, IN, PRP$, NN, .), (PRP, VBD, ...   \n",
       "\n",
       "                                          level2_tok  \\\n",
       "0  ((Going, through, the, forest, is, my, favouri...   \n",
       "1  ((Have, you, ever, dreamt, of, climbing, Mount...   \n",
       "2  ((Recently, ,, there, have, been, many, report...   \n",
       "3  ((Kay, got, another, message, as, she, was, le...   \n",
       "4  ((Mo, was, waiting, in, the, corridor, outside...   \n",
       "\n",
       "                                          level2_pos  \\\n",
       "0  ((VBG, IN, DT, NN, VBZ, PRP$, JJ, NN, IN, DT, ...   \n",
       "1  ((VBP, PRP, RB, VB, IN, VBG, NNP, NNP, CC, VBG...   \n",
       "2  ((RB, ,, EX, VBP, VBN, JJ, NNS, IN, NNS, CC, I...   \n",
       "3  ((NNP, VBD, DT, NN, IN, PRP, VBD, VBG, IN, NN,...   \n",
       "4  ((NNP, VBD, VBG, IN, DT, NN, IN, PRP$, NN, .),...   \n",
       "\n",
       "                                          level3_tok  \\\n",
       "0  ((Going, through, the, forest, is, my, favouri...   \n",
       "1  ((Have, you, ever, dreamt, of, climbing, Mount...   \n",
       "2  ((Small, animals, like, birds, ,, squirrels, ,...   \n",
       "3  ((Kay, got, another, message, as, she, was, le...   \n",
       "4  ((Mo, was, waiting, in, the, corridor, with, h...   \n",
       "\n",
       "                                          level3_pos  \\\n",
       "0  ((VBG, IN, DT, NN, VBZ, PRP$, JJ, NN, IN, DT, ...   \n",
       "1  ((VBP, PRP, RB, VB, IN, VBG, NNP, NNP, CC, VBG...   \n",
       "2  ((JJ, NNS, IN, NNS, ,, NNS, ,, NN, CC, NNS, VB...   \n",
       "3  ((NNP, VBD, DT, NN, IN, PRP, VBD, VBG, IN, NN,...   \n",
       "4  ((NNP, VBD, VBG, IN, DT, NN, IN, PRP$, NN, IN,...   \n",
       "\n",
       "                article_name  \n",
       "0          walk-forest-level  \n",
       "1  amazing-adventurers-level  \n",
       "2         animals-city-level  \n",
       "3                bully-level  \n",
       "4                cheat-level  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_pos_df[\"article_name\"] = df[\"article_name\"].values\n",
    "tok_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_pos_path = \"data/british_council/tok_pos_articles.csv\"\n",
    "prepare_data.save_df(tok_pos_path,tok_pos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_pos_df = prepare_data.load_df(tok_pos_path,all_level_pos_col+all_level_tok_col)\n",
    "df = tok_pos_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text_list = []\n",
    "for pos_col,tok_col,lem_col in zip(*[all_level_pos_col,all_level_tok_col,all_level_lem_col]):\n",
    "    lemmatized_text = df.apply(\n",
    "        lambda x: [[lemmatizer.lemmatize(word,get_wordnet_pos(tag)) for word,tag in zip(*[sent,tags])]\n",
    "                   for sent,tags in zip(*[x[tok_col],x[pos_col]])],axis=1)\n",
    "    df[lem_col] = lemmatized_text\n",
    "    #lemmatized_text_list += [lemmatized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tok_lem_path = \"data/british_council/tok_pos_lem_articles.csv\"\n",
    "prepare_data.save_df(pos_tok_lem_path,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and Sentence Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sent_word_length(text):\n",
    "    n_sent = len(text)\n",
    "    sent_len = [len(words) for words in text]\n",
    "    n_words = sum(sent_len)\n",
    "    word_len = [len(word) for words in text for word in words]\n",
    "    \n",
    "    mean_word_len = np.mean(word_len)\n",
    "    mean_sent_len = np.mean(sent_len)\n",
    "    return mean_word_len,mean_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2.8545627376425857, 8.766666666666667),\n",
       "  (4.081466395112017, 16.366666666666667),\n",
       "  (3.903765690376569, 13.277777777777779),\n",
       "  (3.4817351598173514, 8.342857142857143),\n",
       "  (3.3550802139037432, 12.98611111111111),\n",
       "  (3.722910216718266, 15.75609756097561),\n",
       "  (4.110311750599521, 13.03125),\n",
       "  (3.3088630259623995, 10.844660194174757),\n",
       "  (3.5906148867313914, 13.733333333333333),\n",
       "  (3.831932773109244, 14.875),\n",
       "  (3.8601769911504427, 13.13953488372093),\n",
       "  (3.6666666666666665, 18.085714285714285),\n",
       "  (3.409681227863046, 11.929577464788732),\n",
       "  (3.2223837209302326, 10.920634920634921),\n",
       "  (3.3555878084179973, 11.677966101694915),\n",
       "  (3.9606126914660833, 14.741935483870968),\n",
       "  (3.5828677839851024, 18.517241379310345),\n",
       "  (3.233108108108108, 16.0),\n",
       "  (3.1582867783985105, 12.067415730337078),\n",
       "  (3.3531468531468533, 10.337349397590362),\n",
       "  (3.832129963898917, 16.294117647058822),\n",
       "  (3.6792035398230087, 14.580645161290322))]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*tok_pos_df[[level1_tok_col]].applymap(lambda x: count_sent_word_length(x)).values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
